# -*- coding: utf-8 -*-
"""s18579_gr12c_PRO6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tBLdas7rrmzIcm5wct1UxjMnNDUJuz1e

#Dla danych “CIFAR10 small image classification” z biblioteki Keras zaproponuj i zrealizuj podział tych danych na dane treningowe i dane testowe,
"""

from matplotlib import pyplot as plt
def showImg(x, y):
  i = 0
  while i < len(x):
    print(y[i])
    plt.imshow(x[i])
    plt.show()
    i += 1

def classifierY(y):
  ytemp = y
  ii = 0
  while ii < len(ytemp):
    if ytemp[ii] == 0 or  ytemp[ii] == 1 or  ytemp[ii] == 8 or  ytemp[ii] == 9: ytemp[ii] = 1
    else: ytemp[ii] = 0
    ii += 1
  return ytemp

def classifierX(x):
  return x.astype('float32')/255.0

from keras.datasets import cifar10
from matplotlib import pyplot as plt
from keras.utils import to_categorical
import numpy as np

(X_train, y_train), (X_test, y_test) = cifar10.load_data()


X_train_normalize = classifierX(X_train)
y_train_normalize = classifierY(y_train)

X_test_normalize =  classifierX(X_test)
y_test_normalize =  classifierY(y_test)

class_names = ['animal', 'vehicle']
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(X_train_normalize[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[y_train_normalize[i][0]])
plt.show()

y_train_normalize = to_categorical(y_train_normalize)
y_test_normalize = to_categorical(y_test_normalize)

"""#W oparciu o sieć konwolucyjną, zgodnie z wskazaniami prowadzącego, zaproponuj klasyfikator, klasyfikujący dwie z dziesięciu klas


"""

from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dropout
from keras.layers import Dense
from keras.layers import Flatten
from keras.utils import to_categorical



model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train_normalize, y_train_normalize, epochs=20, batch_size=64, validation_data=(X_train_normalize, y_train_normalize))

model.save('miw_s18579_f_1_model_fit.h5'.format(1))

from tensorflow import keras
model = keras.models.load_model('miw_s18579_f_1_model_fit.h5'.format(1))
loss, acc = model.evaluate(X_test_normalize, y_test_normalize, verbose=0)
print('accuracy: {}'.format(acc))
print('loss: {}'.format(loss))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""#Zaproponuj klasyfikator z jedną, dwiema oraz trzema warstwami konwolucyjnymi,"""

model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train_normalize, y_train_normalize, epochs=20, batch_size=64, validation_data=(X_train_normalize, y_train_normalize))

model.save('miw_s18579_f_2_model_fit.h5'.format(1))

model = keras.models.load_model('miw_s18579_f_2_model_fit.h5'.format(1))
loss, acc = model.evaluate(X_test_normalize, y_test_normalize, verbose=0)
print('accuracy: {}'.format(acc))
print('loss: {}'.format(loss))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Flatten())
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train_normalize, y_train_normalize, epochs=20, batch_size=64, validation_data=(X_train_normalize, y_train_normalize))

model.save('miw_s18579_f_3_model_fit.h5'.format(1))

model = keras.models.load_model('miw_s18579_f_3_model_fit.h5'.format(1))
loss, acc = model.evaluate(X_test_normalize, y_test_normalize, verbose=0)
print('accuracy: {}'.format(acc))
print('loss: {}'.format(loss))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""#Porównaj wyniki z poprzedniego punktu i zaproponuj optymalny klasyfikator dla danego problemu."""